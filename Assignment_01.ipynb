{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBIsb2p2XnkQ"
      },
      "outputs": [],
      "source": [
        "# 11th March 2024\n",
        "# CSC461 – Assignment1 – IDS – Web Scraping\n",
        "# Hamna Shahbaz\n",
        "# CIIT/LHR/FA21-BSE-048\n",
        "# Web-Scraping and Parsing using requests and BeautifulSoup libraries, respectively"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing libraries used in both Questions\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv"
      ],
      "metadata": {
        "id": "IiSUnlkOYeYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 01\n",
        "#Adding Headers and Cookies to prevent 403 Forbidden restriction\n",
        "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
        "cookies = {'cookie_name': 'cookie_value'}\n",
        "url = \"https://www.imdb.com/chart/top/ \"\n",
        "\n",
        "response = requests.get(url, headers=headers, cookies=cookies)\n",
        "\n",
        "soup = BeautifulSoup(response.content, 'html5lib')"
      ],
      "metadata": {
        "id": "Vj8RidPkYA0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Parsing required data by specifying Classes and Divs\n",
        "titles = soup.find_all('div', class_='ipc-title__text')\n",
        "years = soup.find_all('span', class_='sc-b0691f29-8 ilsLEX cli-title-metadata-item')\n",
        "durations = soup.find_all('span', class_='sc-b0691f29-8 ilsLEX cli-title-metadata-item')\n",
        "ratings = soup.find_all('span', class_='ipc-rating-star ipc-rating-star--base ipc-rating-star--imdb ratingGroup--imdb-rating')\n",
        "\n",
        "print(titles, years,durations,ratings)"
      ],
      "metadata": {
        "id": "nsubEIbRYELl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "395087cb-3788-45be-90d6-71d0b914e645"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[] [] [] []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Writing the scraped data into a CSV file\n",
        "file_path = 'Top_250_movies.csv'\n",
        "with open(file_path, 'w', newline='') as file:\n",
        "  writer = csv.writer(file)\n",
        "  for i in titles:\n",
        "    writer.writerows(titles[i], years[i], durations[i], ratings[i])\n",
        "\n",
        "print(\"Data written to csv file\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJxrdlU0dPg4",
        "outputId": "e3895180-0a8c-4d93-c4de-8940634b39df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data written to csv file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 02\n",
        "\n",
        "from openpyxl import Workbook\n",
        "wb  = Workbook()\n",
        "ws = wb.active"
      ],
      "metadata": {
        "id": "DKLTA8hpbc5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = requests.get(\"https://space-facts.com/mars/\")\n",
        "\n",
        "soup = BeautifulSoup(response.content, 'html5lib')\n",
        "\n",
        "table = soup.find('table', id='tablepress-p-mars')\n",
        "for row_i, row in enumerate(table.find_all('tr')):\n",
        "  for col_i, cel in enumerate(table.find_all(['th', 'td'])):\n",
        "    ws.cell(row = row_i+1, column = col_i+1, value = cel.text.strip())\n",
        "\n",
        "wb.save('Mars_profile.xlsx')\n",
        "print(\"Data written to excel file\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7svcKpwZY7-p",
        "outputId": "4396fff1-fa72-40a3-f03b-3f8e69d9a32c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data written to excel file\n"
          ]
        }
      ]
    }
  ]
}